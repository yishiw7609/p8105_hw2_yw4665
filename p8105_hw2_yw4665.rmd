---
title: "p8105_hw2_yw4665"
author: "Yishi Wang"
date: "2025-09-23"
output: github_document
---

## Package calls
Call necessary libraries here:
```{r}
library(tidyverse)
library(readxl)
```

## Problem 1
Read desired data from the local_files folder and assign them to according variables:
```{r}
pols_month_df = read_csv("local_files/fivethirtyeight_datasets/pols-month.csv") |>
  janitor::clean_names()
unemployment_df = read_csv("local_files/fivethirtyeight_datasets/unemployment.csv") |>
  janitor::clean_names()
snp_df = read_csv("local_files/fivethirtyeight_datasets/snp.csv") |>
  janitor::clean_names()
```
Clean the the pols_month dataframe first and assign the result df to 'cleaned_pols_month_df':
```{r}
cleaned_pols_month_df = pols_month_df |> 
  separate("mon", c("year", "month", "day"), "-") |> 
  mutate(
    month = month.name[as.integer(month)],
    president = if_else(prez_gop == 0, "dem", "gop"),
    year = as.numeric(year)
    ) |>
  select(-prez_gop, -prez_dem, -day)
```

Now clean the snp dataframe with similar procedures:
```{r}
cleaned_snp_df = snp_df |>
  separate("date", c("month", "day", "year"), "/") |>
  mutate(
    month = month.name[as.integer(month)],
    # Change the year formatting to match with pols_month_df
    year = if_else(as.integer(year) < 30, as.integer(year) + 2000, as.integer(year) + 1900 ),
  ) |> 
  select(year, month, close)
```

Now tidy the unemployment dataframe to match the previous dataframes:
```{r}
cleaned_unemployment_df = unemployment_df |>
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "unemployment_rate"
    ) |>
  mutate(
    month = month.name[match(month, tolower(month.abb))]
    )
```
Now we combine all three dataframes through two left_joins:
```{r}
pols_snp_unempolyment_df = cleaned_pols_month_df |>
  left_join(cleaned_snp_df, by = c("year", "month")) |>
  left_join(cleaned_unemployment_df, by = c("year", "month"))
```
Three datasets each contains information about an event over a period of time, specifically speaking:

- pos-month: includes number of governors from republican and democrat parties and the party of presidency from 1947-01 to 2015-06
- snp: includes Standard & Poorâ€™s stock market index from 1950-01 to 2015-07
- unempolyment: includes unemployment rate from 1948-01 to 2015-12

By combining the datasets above with date (year-month), we are able to see the impact of politician parties on SnP stock market and unempolyment rate. These data over time may reflect the overall performance of a party or presidency.

## Problem02
First, import the Mr. Trash Wheel sheet and apply changes:
```{r}
mtw_df = read_excel("local_files/202509 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N709") |>
  janitor::clean_names() |>
  mutate(
    sports_balls = as.integer(round(sports_balls)),
    category = "Mr. Trash Wheel",
    year = as.numeric(year),
  )  |>
  filter(!is.na(dumpster))
```

Similarly, for Professor Trash Wheel and Gwynnda datasets:
```{r}
ptw_df = read_excel("local_files/202509 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", range = "A2:M134") |>
  janitor::clean_names() |>
  mutate(
    category = "Professor Trash Wheel"
  ) |>
  filter(!is.na(dumpster))

gftw_df = read_excel("local_files/202509 Trash Wheel Collection Data.xlsx", sheet = "Gwynns Falls Trash Wheel", range = "A2:L351") |>
  janitor::clean_names() |>
  mutate(
    category = "Gwynns Falls Trash Wheel"
  ) |>
  filter(!is.na(dumpster))
```
Now we combine all 3 datasets by stacking them together:
```{r}
all_trash_wheels_df = bind_rows(mtw_df, ptw_df, gftw_df)
```

Lastly, the combined Trash Wheels df contains `r nrow(all_trash_wheels_df)` observations across three wheels (Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda). Key variables include `year`, `month` and `date` (collection date), `weight_tons` and `volume_cubic_yards` (mass and volume of collected trash). `plastic_bottles:sport_balls` (all types of recycled trash) `homes_powered` (estimated number of household to be powered) and `category` (which Trash Wheel contributed). 
```{r}
all_trash_wheels_df |>
  filter(category == "Professor Trash Wheel") |>
  summarise(total = sum(weight_tons, na.rm = TRUE)) |>
  pull(total)
```
We see that Professor Trash Wheel collected a total of 282.26 tons of trash.
```{r}
all_trash_wheels_df |> 
  filter(category == "Gwynns Falls Trash Wheel", year == 2022, month == "June") |> 
  summarise(total = sum(cigarette_butts, na.rm = TRUE)) |> 
  pull(total)
```
And Gwynnda collected 18120 cigarette butts during June 2022.

## Problem 3
First import two datasets:
```{r}
zip_codes_df = read_csv("local_files/zillow_data/Zip Codes.csv") |>
  janitor::clean_names()

zip_zori_df = read_csv("local_files/zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv") |>
  janitor::clean_names() 
```
Perform tidying for zip_codes_df:
```{r}
zip_codes_clean = zip_codes_df |>
  mutate(
    county = str_to_title(county),
    neighborhood = if_else(is.na(neighborhood), NA_character_, str_to_title(neighborhood))
  ) |>
  distinct() |>
  select(zip_code, county, county_fips, county_code, state_fips, file_date, neighborhood, everything())
```

Perform tidying for zip_zori_df:
```{r}
zori_clean = zip_zori_df |>
  pivot_longer(
    cols = contains("x20"),
    names_to = "date",
    values_to = "zori_value",
    values_transform = list(zori_value = as.numeric)
  ) |>
  mutate(
    city = if_else(is.na(city) | city == "", NA_character_, str_to_title(city))
  ) |>
  filter(!is.na(zori_value)) |>
  select(region_id, size_rank, region_name, region_type, state, city, county_name, date, zori_value, metro) 

```








